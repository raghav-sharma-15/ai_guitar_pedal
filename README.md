# AI Guitar Pedal â€” Real-time Genre-Aware FX

[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Audio](https://img.shields.io/badge/Audio-Real--time-informational.svg)
![ML](https://img.shields.io/badge/ML-CNN%20%7C%20MLP-informational.svg)

**TL;DR:** Real-time, genre-aware guitar pedal â€” classifies input and routes tailored FX on the fly.

## 10-sec Demo (Headphones ğŸ§)
- Clean â†’ Rock FX: [docs/audio/clean_rock_before.wav](docs/audio/clean_rock_before.wav) â†’ [docs/audio/clean_rock_after.wav](docs/audio/clean_rock_after.wav)  
- Jazz Riff â†’ Warmth/Chorus: [docs/audio/jazz_before.wav](docs/audio/jazz_before.wav) â†’ [docs/audio/jazz_after.wav](docs/audio/jazz_after.wav)

```mermaid
flowchart LR
  G[ Guitar / Input ]
  I[ Audio Interface or Mic ]
  C[ Real-time Inference / Genre Classifier ]
  FX[ Effect Router: Overdrive, Chorus, EQ, Reverb ]
  O[ Output / Headphones / Amp ]

  G --> I --> C --> FX --> O
```


```bash
pip install -r requirements.txt
python live_guitar_pedal.py  # set --device if needed


A Python-based, real-time guitar effects pedal powered by machine-learning genre classification.  
Supports two pipelines:

- **MLP** on hand-crafted audio features  
- **CNN** on log-mel spectrograms  

Can run **offline** on WAV files or **live** via any USB audio interface.

---

## ğŸš€ Quickstart

These commands assume youâ€™re in the repository root (`AI_GUITAR_PEDAL/`) and have Python 3.9+ installed.

1. **Clone & install dependencies**  
   ```bash
   git clone https://github.com/<your-username>/AI_GUITAR_PEDAL.git
   cd AI_GUITAR_PEDAL
   python3 -m venv venv
   source venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

2. **Download GTZAN dataset**  
   - From Kaggle:  
     https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification  
   - Unzip into `data/gtzan`, so you have e.g.  
     ```
     data/gtzan/blues/blues.00000.wav
     data/gtzan/classical/classical.00000.wav
     â€¦
     ```

3. **Preprocess audio**  
   - Hand-crafted features (MLP):  
     ```bash
     python scripts/preprocess_audio.py features
     # â†’ data/features.npy
     ```  
   - Log-mel spectrograms (CNN):  
     ```bash
     python scripts/preprocess_audio.py spectrogram
     # â†’ data/specs.npz
     ```

4. **Train models**  
   - **MLP** on features:  
     ```bash
     python scripts/train_model.py --model-type mlp --data data/features.npy
     # â†’ models/mlp_best.pth, models/mlp_last.pth, models/scaler.pkl
     ```  
   - **CNN** on spectrograms:  
     ```bash
     python scripts/train_model.py --model-type cnn --data data/specs.npz
     # â†’ models/cnn_best.pth, models/cnn_last.pth
     ```

5. **Offline inference**  
   - **MLP** pipeline:  
     ```bash
     python main.py        --input data/gtzan/blues/blues.00000.wav        --output out_mlp.wav        --model models/mlp_best.pth        --scaler models/scaler.pkl
     ```  
   - **CNN** pipeline:  
     ```bash
     python main_cnn.py        --input data/gtzan/blues/blues.00000.wav        --output out_cnn.wav        --model models/cnn_best.pth
     ```

6. **Live pedal**  
   ```bash
   python live_guitar_pedal.py
   ```  
   Use `--device "<Your Audio Device Name>"` if you have multiple USB interfaces.

---

## ğŸ—‚ï¸ Directory Structure

```
AI_GUITAR_PEDAL/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ gtzan/             # GTZAN WAV files (download manually)
â”‚   â”œâ”€â”€ features.npy       # Generated by preprocess_audio.py
â”‚   â””â”€â”€ specs.npz          # Generated by preprocess_audio.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mlp_best.pth       # Best MLP checkpoint
â”‚   â”œâ”€â”€ mlp_last.pth       # Last MLP checkpoint
â”‚   â”œâ”€â”€ cnn_best.pth       # Best CNN checkpoint
â”‚   â”œâ”€â”€ cnn_last.pth       # Last CNN checkpoint
â”‚   â””â”€â”€ scaler.pkl         # Feature scaler for MLP
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ effects.py         # Genre-specific FX chains
â”‚   â”œâ”€â”€ preprocess_audio.py# Feature & spectrogram extraction
â”‚   â””â”€â”€ train_model.py     # MLP & CNN training routines
â”‚
â”œâ”€â”€ main.py                # Offline MLP inference + FX
â”œâ”€â”€ main_cnn.py            # Offline CNN inference + FX
â”œâ”€â”€ live_guitar_pedal.py   # Real-time audio FX loop
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # This file
```

---

## ğŸ¤ Contributing

1. Fork the repository.  
2. Create a topic branch (`git checkout -b feat/YourFeature`)  
3. Commit your changes (`git commit -m "Add feature"`)  
4. Push and open a Pull Request.

Please follow project code style and update documentation/tests as needed.

---

## ğŸ“ License

This project is licensed under the MIT License â€” see the `LICENSE` file for details.
